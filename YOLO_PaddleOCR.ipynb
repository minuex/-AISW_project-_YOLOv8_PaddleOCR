{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **Receipt OCR solutions for document automation**\n",
    "  \n",
    "# 문서 자동화를 위한 영수증 OCR 솔루션"
   ],
   "id": "7e12fa647be667e1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Installation",
   "id": "2d3be9f0504867b9"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-11T02:37:47.267210Z",
     "start_time": "2024-12-11T02:37:45.011539Z"
    }
   },
   "source": "!pip install easyocr",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: easyocr in ./.venv/lib/python3.12/site-packages (1.7.2)\r\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.12/site-packages (from easyocr) (2.5.1)\r\n",
      "Requirement already satisfied: torchvision>=0.5 in ./.venv/lib/python3.12/site-packages (from easyocr) (0.20.1)\r\n",
      "Requirement already satisfied: opencv-python-headless in ./.venv/lib/python3.12/site-packages (from easyocr) (4.10.0.84)\r\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.12/site-packages (from easyocr) (1.14.1)\r\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from easyocr) (2.1.3)\r\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.12/site-packages (from easyocr) (11.0.0)\r\n",
      "Requirement already satisfied: scikit-image in ./.venv/lib/python3.12/site-packages (from easyocr) (0.24.0)\r\n",
      "Requirement already satisfied: python-bidi in ./.venv/lib/python3.12/site-packages (from easyocr) (0.6.3)\r\n",
      "Requirement already satisfied: PyYAML in ./.venv/lib/python3.12/site-packages (from easyocr) (6.0.2)\r\n",
      "Requirement already satisfied: Shapely in ./.venv/lib/python3.12/site-packages (from easyocr) (2.0.6)\r\n",
      "Requirement already satisfied: pyclipper in ./.venv/lib/python3.12/site-packages (from easyocr) (1.3.0.post6)\r\n",
      "Requirement already satisfied: ninja in ./.venv/lib/python3.12/site-packages (from easyocr) (1.11.1.1)\r\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch->easyocr) (3.16.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.12/site-packages (from torch->easyocr) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch->easyocr) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch->easyocr) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch->easyocr) (2024.10.0)\r\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch->easyocr) (75.4.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.12/site-packages (from torch->easyocr) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch->easyocr) (1.3.0)\r\n",
      "Requirement already satisfied: imageio>=2.33 in ./.venv/lib/python3.12/site-packages (from scikit-image->easyocr) (2.36.0)\r\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in ./.venv/lib/python3.12/site-packages (from scikit-image->easyocr) (2024.9.20)\r\n",
      "Requirement already satisfied: packaging>=21 in ./.venv/lib/python3.12/site-packages (from scikit-image->easyocr) (24.2)\r\n",
      "Requirement already satisfied: lazy-loader>=0.4 in ./.venv/lib/python3.12/site-packages (from scikit-image->easyocr) (0.4)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch->easyocr) (3.0.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T02:39:04.575799Z",
     "start_time": "2024-12-11T02:37:50.699822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install ultralytics  \n",
    "!pip install opencv-python-headless  \n",
    "from ultralytics import YOLO"
   ],
   "id": "aa14ae3f113ee867",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\r\n",
      "  Obtaining dependency information for ultralytics from https://files.pythonhosted.org/packages/d0/a3/87a9d3c9d1e873d922409d18faa2a77c18e3f7a32757fdaca16bb7a889f3/ultralytics-8.3.49-py3-none-any.whl.metadata\r\n",
      "  Downloading ultralytics-8.3.49-py3-none-any.whl.metadata (35 kB)\r\n",
      "Requirement already satisfied: numpy>=1.23.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (2.1.3)\r\n",
      "Collecting numpy>=1.23.0 (from ultralytics)\r\n",
      "  Obtaining dependency information for numpy>=1.23.0 from https://files.pythonhosted.org/packages/75/5b/ca6c8bd14007e5ca171c7c03102d17b4f4e0ceb53957e8c44343a9546dcc/numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\r\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (3.9.2)\r\n",
      "Collecting opencv-python>=4.6.0 (from ultralytics)\r\n",
      "  Obtaining dependency information for opencv-python>=4.6.0 from https://files.pythonhosted.org/packages/66/82/564168a349148298aca281e342551404ef5521f33fba17b388ead0a84dc5/opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in ./.venv/lib/python3.12/site-packages (from ultralytics) (11.0.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in ./.venv/lib/python3.12/site-packages (from ultralytics) (6.0.2)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (2.32.3)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in ./.venv/lib/python3.12/site-packages (from ultralytics) (1.14.1)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (2.5.1)\r\n",
      "Requirement already satisfied: torchvision>=0.9.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (0.20.1)\r\n",
      "Collecting tqdm>=4.64.0 (from ultralytics)\r\n",
      "  Obtaining dependency information for tqdm>=4.64.0 from https://files.pythonhosted.org/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl.metadata\r\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m57.7/57.7 kB\u001B[0m \u001B[31m168.5 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: psutil in ./.venv/lib/python3.12/site-packages (from ultralytics) (6.1.0)\r\n",
      "Collecting py-cpuinfo (from ultralytics)\r\n",
      "  Obtaining dependency information for py-cpuinfo from https://files.pythonhosted.org/packages/e0/a9/023730ba63db1e494a271cb018dcd361bd2c917ba7004c3e49d5daf795a2/py_cpuinfo-9.0.0-py3-none-any.whl.metadata\r\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\r\n",
      "Collecting pandas>=1.1.4 (from ultralytics)\r\n",
      "  Obtaining dependency information for pandas>=1.1.4 from https://files.pythonhosted.org/packages/e1/0c/ad295fd74bfac85358fd579e271cded3ac969de81f62dd0142c426b9da91/pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (89 kB)\r\n",
      "Collecting seaborn>=0.11.0 (from ultralytics)\r\n",
      "  Obtaining dependency information for seaborn>=0.11.0 from https://files.pythonhosted.org/packages/83/11/00d3c3dfc25ad54e731d91449895a79e4bf2384dc3ac01809010ba88f6d5/seaborn-0.13.2-py3-none-any.whl.metadata\r\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\r\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\r\n",
      "  Obtaining dependency information for ultralytics-thop>=2.0.0 from https://files.pythonhosted.org/packages/4a/87/bfd5285f27c23eeec0f609e814a06fc6c7389f37d8703d98e646a9c5fdc3/ultralytics_thop-2.0.13-py3-none-any.whl.metadata\r\n",
      "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\r\n",
      "Collecting pytz>=2020.1 (from pandas>=1.1.4->ultralytics)\r\n",
      "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/11/c3/005fcca25ce078d2cc29fd559379817424e94885510568bc1bc53d7d5846/pytz-2024.2-py2.py3-none-any.whl.metadata\r\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\r\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.1.4->ultralytics)\r\n",
      "  Obtaining dependency information for tzdata>=2022.7 from https://files.pythonhosted.org/packages/a6/ab/7e5f53c3b9d14972843a647d8d7a853969a58aecc7559cb3267302c94774/tzdata-2024.2-py2.py3-none-any.whl.metadata\r\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.4.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\r\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.16.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\r\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (75.4.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\r\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\r\n",
      "Downloading ultralytics-8.3.49-py3-none-any.whl (898 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m898.7/898.7 kB\u001B[0m \u001B[31m114.9 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\r\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl (54.8 MB)\r\n",
      "Using cached pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl (11.4 MB)\r\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\r\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.5/78.5 kB\u001B[0m \u001B[31m39.1 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0mm\r\n",
      "\u001B[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\r\n",
      "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\r\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\r\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\r\n",
      "Installing collected packages: pytz, py-cpuinfo, tzdata, tqdm, numpy, pandas, opencv-python, ultralytics-thop, seaborn, ultralytics\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 2.1.3\r\n",
      "    Uninstalling numpy-2.1.3:\r\n",
      "      Successfully uninstalled numpy-2.1.3\r\n",
      "Successfully installed numpy-1.26.4 opencv-python-4.10.0.84 pandas-2.2.3 py-cpuinfo-9.0.0 pytz-2024.2 seaborn-0.13.2 tqdm-4.67.1 tzdata-2024.2 ultralytics-8.3.49 ultralytics-thop-2.0.13\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: opencv-python-headless in ./.venv/lib/python3.12/site-packages (4.10.0.84)\r\n",
      "Requirement already satisfied: numpy>=1.21.2 in ./.venv/lib/python3.12/site-packages (from opencv-python-headless) (1.26.4)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T05:21:06.194270Z",
     "start_time": "2024-12-12T05:21:02.356896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install paddlepaddle\n",
    "!pip install paddleocr"
   ],
   "id": "78603a2b72563dd8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: paddlepaddle in ./.venv/lib/python3.12/site-packages (2.6.2)\r\n",
      "Requirement already satisfied: httpx in ./.venv/lib/python3.12/site-packages (from paddlepaddle) (0.27.2)\r\n",
      "Requirement already satisfied: numpy>=1.13 in ./.venv/lib/python3.12/site-packages (from paddlepaddle) (1.26.4)\r\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.12/site-packages (from paddlepaddle) (11.0.0)\r\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.12/site-packages (from paddlepaddle) (5.1.1)\r\n",
      "Requirement already satisfied: astor in ./.venv/lib/python3.12/site-packages (from paddlepaddle) (0.8.1)\r\n",
      "Requirement already satisfied: opt-einsum==3.3.0 in ./.venv/lib/python3.12/site-packages (from paddlepaddle) (3.3.0)\r\n",
      "Requirement already satisfied: protobuf>=3.20.2 in ./.venv/lib/python3.12/site-packages (from paddlepaddle) (5.29.1)\r\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.12/site-packages (from httpx->paddlepaddle) (4.6.2.post1)\r\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx->paddlepaddle) (2024.8.30)\r\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx->paddlepaddle) (1.0.6)\r\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.12/site-packages (from httpx->paddlepaddle) (3.10)\r\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from httpx->paddlepaddle) (1.3.1)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->paddlepaddle) (0.14.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: paddleocr in ./.venv/lib/python3.12/site-packages (2.9.1)\r\n",
      "Requirement already satisfied: shapely in ./.venv/lib/python3.12/site-packages (from paddleocr) (2.0.6)\r\n",
      "Requirement already satisfied: scikit-image in ./.venv/lib/python3.12/site-packages (from paddleocr) (0.24.0)\r\n",
      "Requirement already satisfied: imgaug in ./.venv/lib/python3.12/site-packages (from paddleocr) (0.4.0)\r\n",
      "Requirement already satisfied: pyclipper in ./.venv/lib/python3.12/site-packages (from paddleocr) (1.3.0.post6)\r\n",
      "Requirement already satisfied: lmdb in ./.venv/lib/python3.12/site-packages (from paddleocr) (1.5.1)\r\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from paddleocr) (4.67.1)\r\n",
      "Requirement already satisfied: numpy<2.0 in ./.venv/lib/python3.12/site-packages (from paddleocr) (1.26.4)\r\n",
      "Requirement already satisfied: rapidfuzz in ./.venv/lib/python3.12/site-packages (from paddleocr) (3.10.1)\r\n",
      "Requirement already satisfied: opencv-python in ./.venv/lib/python3.12/site-packages (from paddleocr) (4.10.0.84)\r\n",
      "Requirement already satisfied: opencv-contrib-python in ./.venv/lib/python3.12/site-packages (from paddleocr) (4.10.0.84)\r\n",
      "Requirement already satisfied: cython in ./.venv/lib/python3.12/site-packages (from paddleocr) (3.0.11)\r\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.12/site-packages (from paddleocr) (11.0.0)\r\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.12/site-packages (from paddleocr) (6.0.2)\r\n",
      "Requirement already satisfied: python-docx in ./.venv/lib/python3.12/site-packages (from paddleocr) (1.1.2)\r\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.12/site-packages (from paddleocr) (4.12.3)\r\n",
      "Requirement already satisfied: fonttools>=4.24.0 in ./.venv/lib/python3.12/site-packages (from paddleocr) (4.54.1)\r\n",
      "Requirement already satisfied: fire>=0.3.0 in ./.venv/lib/python3.12/site-packages (from paddleocr) (0.7.0)\r\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from paddleocr) (2.32.3)\r\n",
      "Requirement already satisfied: albumentations==1.4.10 in ./.venv/lib/python3.12/site-packages (from paddleocr) (1.4.10)\r\n",
      "Requirement already satisfied: albucore==0.0.13 in ./.venv/lib/python3.12/site-packages (from paddleocr) (0.0.13)\r\n",
      "Requirement already satisfied: tomli>=2.0.1 in ./.venv/lib/python3.12/site-packages (from albucore==0.0.13->paddleocr) (2.2.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in ./.venv/lib/python3.12/site-packages (from albucore==0.0.13->paddleocr) (4.12.2)\r\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in ./.venv/lib/python3.12/site-packages (from albucore==0.0.13->paddleocr) (4.10.0.84)\r\n",
      "Requirement already satisfied: scipy>=1.10.0 in ./.venv/lib/python3.12/site-packages (from albumentations==1.4.10->paddleocr) (1.14.1)\r\n",
      "Requirement already satisfied: scikit-learn>=1.3.2 in ./.venv/lib/python3.12/site-packages (from albumentations==1.4.10->paddleocr) (1.6.0)\r\n",
      "Requirement already satisfied: pydantic>=2.7.0 in ./.venv/lib/python3.12/site-packages (from albumentations==1.4.10->paddleocr) (2.10.3)\r\n",
      "Requirement already satisfied: termcolor in ./.venv/lib/python3.12/site-packages (from fire>=0.3.0->paddleocr) (2.5.0)\r\n",
      "Requirement already satisfied: networkx>=2.8 in ./.venv/lib/python3.12/site-packages (from scikit-image->paddleocr) (3.4.2)\r\n",
      "Requirement already satisfied: imageio>=2.33 in ./.venv/lib/python3.12/site-packages (from scikit-image->paddleocr) (2.36.0)\r\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in ./.venv/lib/python3.12/site-packages (from scikit-image->paddleocr) (2024.9.20)\r\n",
      "Requirement already satisfied: packaging>=21 in ./.venv/lib/python3.12/site-packages (from scikit-image->paddleocr) (24.2)\r\n",
      "Requirement already satisfied: lazy-loader>=0.4 in ./.venv/lib/python3.12/site-packages (from scikit-image->paddleocr) (0.4)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.12/site-packages (from beautifulsoup4->paddleocr) (2.6)\r\n",
      "Requirement already satisfied: six in ./.venv/lib/python3.12/site-packages (from imgaug->paddleocr) (1.16.0)\r\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (from imgaug->paddleocr) (3.9.2)\r\n",
      "Requirement already satisfied: lxml>=3.1.0 in ./.venv/lib/python3.12/site-packages (from python-docx->paddleocr) (5.3.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->paddleocr) (3.4.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->paddleocr) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->paddleocr) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->paddleocr) (2024.8.30)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.7.0->albumentations==1.4.10->paddleocr) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.7.0->albumentations==1.4.10->paddleocr) (2.27.1)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn>=1.3.2->albumentations==1.4.10->paddleocr) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn>=1.3.2->albumentations==1.4.10->paddleocr) (3.5.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->imgaug->paddleocr) (1.3.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib->imgaug->paddleocr) (0.12.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->imgaug->paddleocr) (1.4.7)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->imgaug->paddleocr) (3.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib->imgaug->paddleocr) (2.9.0.post0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. YOLO Text Detection Training\n",
    "   - dataset : 400 images of English and Korean receipts\n",
    "   - Using colab GPU"
   ],
   "id": "c0decfe302783b8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = YOLO('yolov8m.pt')  # YOLOv8m 사용\n",
    "\n",
    "model.train(\n",
    "    data=\"/content/drive/MyDrive/AISW_project/dataset/data.yaml\",\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    name=\"receipt_detection\",\n",
    "    device=0,\n",
    "    patience = 20,\n",
    "    augment = True\n",
    ")"
   ],
   "id": "e5c2af49284dcac3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.2. YOLO Text Detection Visualization",
   "id": "7124b337e6c84da6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T11:02:24.090176Z",
     "start_time": "2024-12-17T11:02:18.140571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# YOLOv8 모델 불러오기 (best.pt 파일 경로 지정)\n",
    "model = YOLO('best.pt')  # 학습된 best.pt 경로\n",
    "\n",
    "# 테스트 이미지 경로\n",
    "test_image_path = 'test_image.jpg'\n",
    "\n",
    "# 이미지 로드\n",
    "img = cv2.imread(test_image_path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 모델 예측\n",
    "results = model(img_rgb)\n",
    "\n",
    "# 첫 번째 결과 객체 가져오기 (list 형식이므로 첫 번째 결과에 접근)\n",
    "result = results[0]\n",
    "\n",
    "# 예측 결과 시각화\n",
    "result.show()  # 예측된 결과를 이미지에 시각화\n",
    "\n",
    "# 예측된 바운딩 박스 출력 (클래스, confidence, 바운딩 박스 좌표)\n",
    "boxes = result.boxes  # 예측된 객체들\n",
    "for box in boxes:\n",
    "    # 바운딩 박스를 넘파이 배열로 변환\n",
    "    xywh = box.xywh.cpu().numpy()  # `.cpu().numpy()`로 텐서를 넘파이 배열로 변환\n",
    "    cls = box.cls.item()  # 클래스 ID\n",
    "    confidence = box.conf.item()  # 신뢰도\n",
    "\n",
    "    print(f\"Class: {cls}, Confidence: {confidence:.2f}, Bounding Box (xywh): {xywh}\")\n"
   ],
   "id": "c858012830bce6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 1 date_time, 3 items, 1 receipt, 1 store, 1 total, 851.8ms\n",
      "Speed: 11.9ms preprocess, 851.8ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Class: 2.0, Confidence: 0.99, Bounding Box (xywh): [[     1139.5      1511.1        1430      3022.2]]\n",
      "Class: 0.0, Confidence: 0.89, Bounding Box (xywh): [[     956.09      894.98      542.34      92.471]]\n",
      "Class: 3.0, Confidence: 0.87, Bounding Box (xywh): [[     672.51      484.58       433.9      127.55]]\n",
      "Class: 1.0, Confidence: 0.84, Bounding Box (xywh): [[     660.42      1141.2      369.19      83.394]]\n",
      "Class: 4.0, Confidence: 0.81, Bounding Box (xywh): [[     1089.3      1594.2      1234.8      83.819]]\n",
      "Class: 1.0, Confidence: 0.77, Bounding Box (xywh): [[     593.73      1212.5      248.27      69.255]]\n",
      "Class: 1.0, Confidence: 0.27, Bounding Box (xywh): [[     753.65      1282.1      569.57      82.491]]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.2. YOLO Text Detection Testing  \n",
    "- dataset : 30 images of Korean receipts\n",
    "- Using colab GPU"
   ],
   "id": "274c99096bd9b1da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import yaml\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 테스트 데이터셋 경로 설정\n",
    "TEST_IMAGES_DIR = \"/content/drive/MyDrive/AISW_project/test/test/images\"  # 테스트 이미지가 저장된 디렉토리 경로\n",
    "TEST_LABELS_DIR = \"/content/drive/MyDrive/AISW_project/test/test/labels\"  # 테스트 라벨 파일이 저장된 디렉토리 경로 (YOLO 포맷)\n",
    "MODEL_PATH = \"/content/best.pt\"  # 학습된 모델 경로\n",
    "\n",
    "# YOLOv8 모델 로드\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "# 테스트 데이터셋 준비\n",
    "if not os.path.exists(TEST_IMAGES_DIR):\n",
    "    raise FileNotFoundError(f\"Test images directory not found: {TEST_IMAGES_DIR}\")\n",
    "if not os.path.exists(TEST_LABELS_DIR):\n",
    "    raise FileNotFoundError(f\"Test labels directory not found: {TEST_LABELS_DIR}\")\n",
    "\n",
    "# YOLOv8에서 평가를 위해 데이터셋 설정 파일 생성\n",
    "DATA_CONFIG_PATH = \"dataset.yaml\"\n",
    "data_config = {\n",
    "    'path': '.',\n",
    "    'train': '',  # 평가 단계에서는 필요 없음\n",
    "    'val': '',    # 평가 단계에서는 필요 없음\n",
    "    'test': TEST_IMAGES_DIR,\n",
    "    'names': {0: 'class_0', 1: 'class_1', 2: 'class_2', 3: 'class_3', 4: 'class_4'}  # 클래스 이름 설정\n",
    "}\n",
    "\n",
    "with open(DATA_CONFIG_PATH, 'w') as f:\n",
    "    yaml.dump(data_config, f)\n",
    "\n",
    "# 모델 평가\n",
    "results = model.val(data=DATA_CONFIG_PATH, imgsz=640, split='test')\n",
    "\n",
    "# 모델 평가 결과 출력\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(f\"Precision (mAP@0.5): {results.box.map50:.4f}\")\n",
    "print(f\"Precision (mAP@0.5:0.95): {results.box.map:.4f}\")\n",
    "print(f\"Overall Fitness: {results.box.fitness():.4f}\")\n",
    "print(f\"Recall (Mean): {results.box.mr():.4f}\")  # Mean Recall\n",
    "\n",
    "\n",
    "# 시각화\n",
    "print(\"\\nGenerating Detection Results...\")\n",
    "PREDICTIONS_DIR = \"runs/predict/test\"\n",
    "shutil.rmtree(PREDICTIONS_DIR, ignore_errors=True)\n",
    "model.predict(source=TEST_IMAGES_DIR, save=True, save_txt=True, conf=0.25)\n",
    "\n",
    "# 결과 이미지 시각화\n",
    "def visualize_results(image_dir, results_dir):\n",
    "    image_paths = list(Path(image_dir).rglob(\"*.jpg\"))  # jpg 이미지만 사용\n",
    "    result_images = list(Path(results_dir).rglob(\"*.jpg\"))\n",
    "\n",
    "    for image_path, result_image_path in zip(image_paths, result_images):\n",
    "        # 원본 이미지 로드\n",
    "        original_image = cv2.imread(str(image_path))\n",
    "        original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 결과 이미지 로드\n",
    "        result_image = cv2.imread(str(result_image_path))\n",
    "        result_image = cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 시각화\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(\"Original Image\")\n",
    "        plt.imshow(original_image)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(\"Detection Result\")\n",
    "        plt.imshow(result_image)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "visualize_results(TEST_IMAGES_DIR, PREDICTIONS_DIR)"
   ],
   "id": "72436f3d5d05fa66"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Pre-Processing",
   "id": "663dba5f528332a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T05:22:31.896605Z",
     "start_time": "2024-12-12T05:22:31.887380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_for_ocr(image):\n",
    "    \"\"\"\n",
    "    이미지를 전처리하여 OCR 성능을 향상\n",
    "    그레이스케일, 이진화, 노이즈 제거, 대비 조정 등을 포함\n",
    "    \"\"\"\n",
    "    # 1. 그레이스케일 변환\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 2. 이진화 (Otsu의 이진화 기법 사용)\n",
    "    _, binarized_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # 3. 노이즈 제거 (GaussianBlur 사용)\n",
    "    denoised_image = cv2.GaussianBlur(binarized_image, (5, 5), 0)\n",
    "\n",
    "    # 4. 대비 조정 (이미지 대비 향상)\n",
    "    contrast_image = cv2.convertScaleAbs(denoised_image, alpha=1.5, beta=0)\n",
    "\n",
    "    # 5. 기울기 보정 (이미지 회전 보정)\n",
    "    coords = np.column_stack(np.where(contrast_image > 0))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = contrast_image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated_image = cv2.warpAffine(contrast_image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "    return rotated_image\n",
    "\n",
    "# 전처리를 거친 이미지를 EasyOCR로 텍스트 인식\n",
    "def ocr_with_preprocessing(image, reader):\n",
    "    \n",
    "    # 전처리 함수 호출\n",
    "    preprocessed_image = preprocess_for_ocr(image)\n",
    "\n",
    "    # EasyOCR로 텍스트 인식\n",
    "    ocr_result = reader.readtext(preprocessed_image)\n",
    "\n",
    "    return ocr_result\n"
   ],
   "id": "80b819e3d78f8d21",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T05:21:19.038070Z",
     "start_time": "2024-12-12T05:21:19.034688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 이미지 크기 조정 함수 (이미지 확대하여 OCR 성능을 향상)\n",
    "def resize_for_ocr(image):\n",
    "    height, width = image.shape[:2]\n",
    "    new_width = width * 2  # 두 배로 확대\n",
    "    new_height = height * 2\n",
    "    resized_image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_LINEAR)\n",
    "    return resized_image"
   ],
   "id": "264fd357dea78eaa",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. YOLO_EasyOCR Pipeline  \n",
    "- store, date_time, total : 1 Bounding Box with Highest Confidence \n",
    "- Item : All Bounding Box with Confidence > 0.5"
   ],
   "id": "b6c2c38c0d737c69"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T20:17:11.351820Z",
     "start_time": "2024-12-11T20:17:04.877047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from easyocr import Reader\n",
    "from math import atan2, degrees\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "\n",
    "# YOLOv8 모델 로드\n",
    "model = YOLO('best.pt') \n",
    "\n",
    "# 테스트 이미지 경로\n",
    "image_path = \"test_image.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# YOLOv8으로 이미지 처리\n",
    "results = model(image)\n",
    "\n",
    "# 클래스별로 검출 결과 저장\n",
    "detections_by_class = {0: [], 1: [], 3: [], 4: []}\n",
    "\n",
    "# 임계값 설정 (신뢰도 기준)\n",
    "confidence_threshold = 0.45\n",
    "\n",
    "# YOLO 모델 결과에서 바운딩 박스를 추출\n",
    "for result in results:\n",
    "    boxes = result.boxes  # YOLOv8 결과에서 박스를 추출\n",
    "    for box in boxes:\n",
    "        confidence = box.conf[0].item()\n",
    "        class_id = int(box.cls[0].item())\n",
    "\n",
    "        #\n",
    "        if confidence >= confidence_threshold:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())  # 좌표 추출\n",
    "            #클래스 0,1,3,4에 대해서만 처리\n",
    "            if class_id in detections_by_class:\n",
    "                detections_by_class[class_id].append((confidence, x1, y1, x2, y2))\n",
    "\n",
    "# 클래스 0, 3, 4번: 신뢰도가 가장 높은 영역만 선택\n",
    "selected_detections = []\n",
    "for class_id in [0, 3, 4]:\n",
    "    if detections_by_class[class_id]:\n",
    "        best_box = max(detections_by_class[class_id], key=lambda x: x[0])  # 신뢰도 기준 최댓값\n",
    "        selected_detections.append((class_id, *best_box))\n",
    "\n",
    "# 클래스 1번은 모든 결과를 추가 (임계값을 만족하는 모든 검출 결과)\n",
    "for detection in detections_by_class[1]:\n",
    "    selected_detections.append((1, *detection))\n",
    "\n",
    "# 클래스별 색상 설정\n",
    "class_colors = {\n",
    "    0: (255, 0, 0),    # 빨강\n",
    "    1: (0, 255, 0),    # 초록\n",
    "    3: (0, 0, 255),    # 파랑\n",
    "    4: (255, 255, 0)   # 노랑\n",
    "}\n",
    "\n",
    "# EasyOCR Reader 초기화 (한국어 지원)\n",
    "reader = Reader(['ko', 'en'])\n",
    "\n",
    "# 선택된 영역에서 EasyOCR 텍스트 인식 수행\n",
    "for detection in selected_detections:\n",
    "    class_id, confidence, x1, y1, x2, y2 = detection\n",
    "\n",
    "    # 검출된 영역 자르기\n",
    "    cropped_image = image[y1:y2, x1:x2]\n",
    "\n",
    "    # 이미지 크기 조정 함수 적용\n",
    "    cropped_image = resize_for_ocr(cropped_image)\n",
    "\n",
    "    # EasyOCR로 텍스트 인식\n",
    "    ocr_result = reader.readtext(cropped_image)\n",
    "\n",
    "     # 텍스트를 하나의 문장으로 합치기\n",
    "    combined_text = \" \".join([text for _, text, _ in ocr_result])\n",
    "\n",
    "\n",
    "    print(f\"\\n[Detection] Class: {class_id}, Confidence: {confidence}\")\n",
    "    for bbox, text, text_conf in ocr_result:\n",
    "        print(f\"Detected Text: {text}, Confidence: {text_conf}\")\n"
   ],
   "id": "a4abcbd3db1c6dde",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 1 date_time, 1 item, 1 receipt, 1 total, 234.0ms\n",
      "Speed: 2.5ms preprocess, 234.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "[Detection] Class: 0, Confidence: 0.8465574383735657\n",
      "Detected Text: 2022-06-22, Confidence: 0.8919151120107556\n",
      "Detected Text: 18:56:28, Confidence: 0.8791125589447442\n",
      "\n",
      "[Detection] Class: 4, Confidence: 0.868303656578064\n",
      "Detected Text: 합 계 금액, Confidence: 0.6370755281372791\n",
      "Detected Text: 5,500, Confidence: 0.9997636645409276\n",
      "\n",
      "[Detection] Class: 1, Confidence: 0.8734450340270996\n",
      "Detected Text: 수제바닐라반라떼, Confidence: 0.36531331590879956\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.1 YOLO_Paddle OCR Pipeline",
   "id": "e0c52fed0ad935d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T19:49:38.296084Z",
     "start_time": "2024-12-11T19:49:06.464385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from paddleocr import PaddleOCR\n",
    "import numpy as np\n",
    "\n",
    "# YOLOv8 모델 로드\n",
    "model = YOLO('best.pt')\n",
    "\n",
    "# 테스트 이미지 경로\n",
    "image_path = \"test_image.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# YOLOv8으로 이미지 처리\n",
    "results = model(image)\n",
    "result = results[0]  # 단일 이미지 처리 시\n",
    "\n",
    "# 클래스별로 검출 결과 저장\n",
    "detections_by_class = {0: [], 1: [], 3: [], 4: []}\n",
    "confidence_threshold = 0.45\n",
    "\n",
    "# YOLO 모델 결과에서 바운딩 박스 추출\n",
    "for box in result.boxes:\n",
    "    confidence = box.conf[0].item()\n",
    "    class_id = int(box.cls[0].item())\n",
    "\n",
    "    if class_id in detections_by_class and confidence >= confidence_threshold:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "        detections_by_class[class_id].append((confidence, x1, y1, x2, y2))\n",
    "\n",
    "# 클래스 0, 3, 4: 신뢰도 가장 높은 영역만 선택\n",
    "selected_detections = []\n",
    "for class_id in [0, 3, 4]:\n",
    "    if detections_by_class[class_id]:\n",
    "        best_box = max(detections_by_class[class_id], key=lambda x: x[0])\n",
    "        selected_detections.append((class_id, *best_box))\n",
    "\n",
    "# 클래스 1: 모든 결과 추가\n",
    "selected_detections.extend([(1, *det) for det in detections_by_class[1]])\n",
    "\n",
    "# PaddleOCR Reader 초기화\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='korean', det_db_box_thresh=0.5)\n",
    "\n",
    "# 선택된 영역에서 OCR 수행\n",
    "for detection in selected_detections:\n",
    "    class_id, confidence, x1, y1, x2, y2 = detection\n",
    "\n",
    "    # 검출된 영역 자르기 (BGR -> RGB 변환)\n",
    "    cropped_image = cv2.cvtColor(image[y1:y2, x1:x2], cv2.COLOR_BGR2RGB)\n",
    "    # PaddleOCR로 텍스트 인식\n",
    "    ocr_result = ocr.ocr(cropped_image, det=False)\n",
    "\n",
    "    # 결과 처리\n",
    "    combined_text = \"\"\n",
    "    if ocr_result:\n",
    "        combined_text = \" \".join(\n",
    "            [text_info[0] for line in ocr_result for text_info in line]\n",
    "        )\n",
    "        for line in ocr_result:\n",
    "            for text_info in line:\n",
    "                text, conf = text_info  # 텍스트와 신뢰도 추출\n",
    "                print(f\"Detected Text: {text}, Class: {class_id}, Confidence: {conf}\")\n",
    "  "
   ],
   "id": "c771cab922f1a3c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 1 date_time, 3 items, 1 receipt, 1 store, 1 total, 283.2ms\n",
      "Speed: 10.3ms preprocess, 283.2ms inference, 11.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "download https://paddleocr.bj.bcebos.com/PP-OCRv3/multilingual/Multilingual_PP-OCRv3_det_infer.tar to /Users/minseokim/.paddleocr/whl/det/ml/Multilingual_PP-OCRv3_det_infer/Multilingual_PP-OCRv3_det_infer.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3762/3762 [00:01<00:00, 3107.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download https://paddleocr.bj.bcebos.com/PP-OCRv4/multilingual/korean_PP-OCRv4_rec_infer.tar to /Users/minseokim/.paddleocr/whl/rec/korean/korean_PP-OCRv4_rec_infer/korean_PP-OCRv4_rec_infer.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23810/23810 [00:05<00:00, 4233.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar to /Users/minseokim/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer/ch_ppocr_mobile_v2.0_cls_infer.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2138/2138 [00:00<00:00, 2543.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/12/12 04:49:34] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/Users/minseokim/.paddleocr/whl/det/ml/Multilingual_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.5, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/Users/minseokim/.paddleocr/whl/rec/korean/korean_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/Users/minseokim/PycharmProjects/AISW_project/.venv/lib/python3.12/site-packages/paddleocr/ppocr/utils/dict/korean_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/Users/minseokim/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='korean', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Text: 20241-21 13:13:46 , Class: 0, Confidence: 0.9183201193809509\n",
      "Detected Text: Leafful, Class: 3, Confidence: 0.9767846465110779\n",
      "Detected Text: 합게12000, Class: 4, Confidence: 0.7319976687431335\n",
      "Detected Text: 크림카라멜D0, Class: 1, Confidence: 0.8445944786071777\n",
      "Detected Text: CafHot, Class: 1, Confidence: 0.9926131367683411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# 검출 영역 시각화 (원본 이미지에 표시)\\n    color = class_colors.get(class_id, (0, 255, 255))  # 기본값: 하늘색\\n    cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\\n\\n    # 텍스트 추가 (Pillow 사용)\\n    if combined_text:\\n        pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))  # OpenCV 이미지를 PIL로 변환\\n        draw = ImageDraw.Draw(pil_image)\\n        font_path = \"/content/PretendardVariable.ttf\"  # 한글 폰트 파일 경로\\n        font = ImageFont.truetype(font_path, 50)  # 폰트 크기 조정\\n\\n        # 텍스트 표시 (텍스트가 박스 영역 밖으로 나가지 않도록 y1 위치 조정)\\n        draw.text((x1, max(y1 - 30, 0)), combined_text, font=font, fill=(255, 255, 255))  # 흰색 텍스트\\n\\n        # PIL 이미지를 다시 OpenCV 이미지로 변환\\n        image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\\n\\n# 최종 이미지 표시 (Colab 환경)\\nfrom google.colab.patches import cv2_imshow\\ncv2_imshow(image)  # OpenCV 이미지 표시\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Final **YOLO_PaddleOCR** Pipeline (+Post-Processing)",
   "id": "a633afe23f56c44c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T11:00:38.501915Z",
     "start_time": "2024-12-17T11:00:26.498941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from paddleocr import PaddleOCR\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# YOLOv8 모델 로드\n",
    "model = YOLO('best.pt')\n",
    "\n",
    "# 테스트 이미지 경로\n",
    "image_path = \"test_image.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# YOLOv8으로 이미지 처리\n",
    "results = model(image)\n",
    "result = results[0]  # 단일 이미지 처리 시\n",
    "\n",
    "# 클래스별로 검출 결과 저장\n",
    "detections_by_class = {0: [], 1: [], 3: [], 4: []}\n",
    "confidence_threshold = 0.45\n",
    "\n",
    "# YOLO 모델 결과에서 바운딩 박스 추출\n",
    "for box in result.boxes:\n",
    "    confidence = box.conf[0].item()\n",
    "    class_id = int(box.cls[0].item())\n",
    "\n",
    "    if class_id in detections_by_class and confidence >= confidence_threshold:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "        detections_by_class[class_id].append((confidence, x1, y1, x2, y2))\n",
    "\n",
    "# 클래스 0, 3, 4: 신뢰도 가장 높은 영역만 선택\n",
    "selected_detections = []\n",
    "for class_id in [0, 3, 4]:\n",
    "    if detections_by_class[class_id]:\n",
    "        best_box = max(detections_by_class[class_id], key=lambda x: x[0])\n",
    "        selected_detections.append((class_id, *best_box))\n",
    "\n",
    "# 클래스 1: 모든 결과 추가\n",
    "selected_detections.extend([(1, *det) for det in detections_by_class[1]])\n",
    "\n",
    "# PaddleOCR Reader 초기화\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='korean', det_db_box_thresh=0.5)\n",
    "\n",
    "# 구조화된 데이터 저장\n",
    "structured_data = {\n",
    "    \"store_name\": None,\n",
    "    \"date_time\": None,\n",
    "    \"total\": None,\n",
    "    \"items\": []\n",
    "}\n",
    "\n",
    "# 선택된 영역에서 OCR 수행\n",
    "for detection in selected_detections:\n",
    "    class_id, confidence, x1, y1, x2, y2 = detection\n",
    "\n",
    "    # 검출된 영역 자르기 (BGR -> RGB 변환)\n",
    "    cropped_image = cv2.cvtColor(image[y1:y2, x1:x2], cv2.COLOR_BGR2RGB)\n",
    "    # PaddleOCR로 텍스트 인식\n",
    "    ocr_result = ocr.ocr(cropped_image, det=False)\n",
    "\n",
    "    # 결과 처리\n",
    "    combined_text = \"\"\n",
    "    if ocr_result:\n",
    "        combined_text = \" \".join(\n",
    "            [text_info[0] for line in ocr_result for text_info in line]\n",
    "        )\n",
    "        if class_id == 0:  # 날짜 처리\n",
    "            try:\n",
    "                structured_data[\"date_time\"] = datetime.strptime(\n",
    "                    combined_text, \"%Y-%m-%d %H:%M:%S\"\n",
    "                )\n",
    "            except ValueError:\n",
    "                print(f\"Invalid date format: {combined_text}\")\n",
    "        elif class_id == 4:  # 총 금액 숫자만 추출\n",
    "            total_match = \"\".join(filter(str.isdigit, combined_text))\n",
    "            structured_data[\"total\"] = int(total_match) if total_match.isdigit() else None\n",
    "        elif class_id == 1:  # 품목\n",
    "            structured_data[\"items\"].append(combined_text)\n",
    "        elif class_id == 3:  # 상호명\n",
    "            structured_data[\"store_name\"] = combined_text\n",
    "\n",
    "# 최종 구조화된 데이터 출력\n",
    "print(\"=== Structured Data ===\")\n",
    "print(f\"Store Name: {structured_data['store_name']}\")\n",
    "print(f\"Date and Time: {structured_data['date_time']}\")\n",
    "print(f\"Total Amount: {structured_data['total']:,} 원\" if structured_data[\"total\"] else \"Total Amount: Not detected\")\n",
    "print(\"Items:\")\n",
    "for item in structured_data[\"items\"]:\n",
    "    print(f\"  - {item}\")\n"
   ],
   "id": "9dd8406d838b1baa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 1 date_time, 1 item, 1 receipt, 1 total, 267.7ms\n",
      "Speed: 5.9ms preprocess, 267.7ms inference, 8.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "[2024/12/17 20:00:35] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/Users/minseokim/.paddleocr/whl/det/ml/Multilingual_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.5, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/Users/minseokim/.paddleocr/whl/rec/korean/korean_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/Users/minseokim/PycharmProjects/AISW_project/.venv/lib/python3.12/site-packages/paddleocr/ppocr/utils/dict/korean_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/Users/minseokim/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='korean', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "=== Structured Data ===\n",
      "Store Name: None\n",
      "Date and Time: 2022-06-22 18:56:28\n",
      "Total Amount: 5,500 원\n",
      "Items:\n",
      "  - 수제바닐라빈라떼\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
